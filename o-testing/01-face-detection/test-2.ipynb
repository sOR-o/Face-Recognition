{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24267,
     "status": "ok",
     "timestamp": 1697279207309,
     "user": {
      "displayName": "Saurabh Kushwaha",
      "userId": "11030038731599583514"
     },
     "user_tz": -330
    },
    "id": "uAZNcnZ8fes0",
    "outputId": "5191c483-3651-4876-cc02-7cb7de3fd26b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (8.0.200)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from ultralytics) (3.8.0)\n",
      "Requirement already satisfied: numpy>=1.22.2 in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from ultralytics) (1.26.1)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from ultralytics) (4.8.1.78)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from ultralytics) (10.1.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from ultralytics) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.23.0 in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from ultralytics) (2.31.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from ultralytics) (1.11.3)\n",
      "Requirement already satisfied: torch>=1.8.0 in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from ultralytics) (2.1.0)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from ultralytics) (0.16.0)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from ultralytics) (4.66.1)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from ultralytics) (2.1.1)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from ultralytics) (0.13.0)\n",
      "Requirement already satisfied: psutil in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from ultralytics) (5.9.6)\n",
      "Requirement already satisfied: py-cpuinfo in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: thop>=0.1.1 in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from ultralytics) (0.1.1.post2209072238)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (4.43.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (23.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2023.7.22)\n",
      "Requirement already satisfied: filelock in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (4.8.0)\n",
      "Requirement already satisfied: sympy in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.2)\n",
      "Requirement already satisfied: jinja2 in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (2023.9.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: gradio in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (3.50.0)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from gradio) (23.2.1)\n",
      "Requirement already satisfied: altair<6.0,>=4.2.0 in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from gradio) (5.1.2)\n",
      "Requirement already satisfied: fastapi in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from gradio) (0.104.0)\n",
      "Requirement already satisfied: ffmpy in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from gradio) (0.3.1)\n",
      "Requirement already satisfied: gradio-client==0.6.1 in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from gradio) (0.6.1)\n",
      "Requirement already satisfied: httpx in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from gradio) (0.25.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.14.0 in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from gradio) (0.18.0)\n",
      "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from gradio) (6.1.0)\n",
      "Requirement already satisfied: jinja2<4.0 in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from gradio) (3.1.2)\n",
      "Requirement already satisfied: markupsafe~=2.0 in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from gradio) (2.1.3)\n",
      "Requirement already satisfied: matplotlib~=3.0 in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from gradio) (3.8.0)\n",
      "Requirement already satisfied: numpy~=1.0 in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from gradio) (1.26.1)\n",
      "Requirement already satisfied: orjson~=3.0 in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from gradio) (3.9.9)\n",
      "Requirement already satisfied: packaging in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from gradio) (23.2)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from gradio) (2.1.1)\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from gradio) (10.1.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4 in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from gradio) (2.4.2)\n",
      "Requirement already satisfied: pydub in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from gradio) (0.0.6)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from gradio) (6.0.1)\n",
      "Requirement already satisfied: requests~=2.0 in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from gradio) (2.31.0)\n",
      "Requirement already satisfied: semantic-version~=2.0 in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from gradio) (4.8.0)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from gradio) (0.23.2)\n",
      "Requirement already satisfied: websockets<12.0,>=10.0 in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from gradio) (11.0.3)\n",
      "Requirement already satisfied: fsspec in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from gradio-client==0.6.1->gradio) (2023.9.2)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from altair<6.0,>=4.2.0->gradio) (4.19.1)\n",
      "Requirement already satisfied: toolz in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from altair<6.0,>=4.2.0->gradio) (0.12.0)\n",
      "Requirement already satisfied: filelock in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from huggingface-hub>=0.14.0->gradio) (3.12.4)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from huggingface-hub>=0.14.0->gradio) (4.66.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (4.43.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2023.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4->gradio) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4->gradio) (2.10.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from requests~=2.0->gradio) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from requests~=2.0->gradio) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from requests~=2.0->gradio) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from requests~=2.0->gradio) (2023.7.22)\n",
      "Requirement already satisfied: click>=7.0 in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from uvicorn>=0.14.0->gradio) (8.1.7)\n",
      "Requirement already satisfied: h11>=0.8 in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from uvicorn>=0.14.0->gradio) (0.14.0)\n",
      "Requirement already satisfied: anyio<4.0.0,>=3.7.1 in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from fastapi->gradio) (3.7.1)\n",
      "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from fastapi->gradio) (0.27.0)\n",
      "Requirement already satisfied: httpcore<0.19.0,>=0.18.0 in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from httpx->gradio) (0.18.0)\n",
      "Requirement already satisfied: sniffio in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from httpx->gradio) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from anyio<4.0.0,>=3.7.1->fastapi->gradio) (1.1.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.10.6)\n",
      "Requirement already satisfied: six>=1.5 in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: pandas in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (2.1.1)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from pandas) (1.26.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/saurabh/Documents/projects/Face-Recognition/venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "!pip install ultralytics\n",
    "!pip install gradio\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26738,
     "status": "ok",
     "timestamp": 1697275435891,
     "user": {
      "displayName": "Saurabh Kushwaha",
      "userId": "11030038731599583514"
     },
     "user_tz": -330
    },
    "id": "vqNFLrG1ffHa",
    "outputId": "2fbf4564-bef1-426c-d6a4-5084f70c40bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary library 'drive' from the 'google.colab' package\n",
    "from google.colab import drive\n",
    "\n",
    "# Mount (link) your Google Drive with the Colab notebook\n",
    "# When you run this cell, it will prompt you to visit a link,\n",
    "# authorize access, and provide an authentication code.\n",
    "# After successful authentication, your Google Drive will be mounted\n",
    "# and accessible within the '/content/drive' directory.\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hHcRMLChf2zF"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from ultralytics import YOLO  # Import YOLO model from Ultralytics\n",
    "from ultralytics.engine.results import Results  # Import Results from Ultralytics\n",
    "import gradio as gr  # Import Gradio for building an interface\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1697279235884,
     "user": {
      "displayName": "Saurabh Kushwaha",
      "userId": "11030038731599583514"
     },
     "user_tz": -330
    },
    "id": "E8ht0rffgHEt",
    "outputId": "55012340-3865-409c-d114-51b00a243694"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    897664  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \n",
      "YOLOv8n summary: 225 layers, 3157200 parameters, 3157184 gradients, 8.9 GFLOPs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a YOLO model instance using a YAML configuration file ('yolov8n.yaml')\n",
    "# This YAML file defines the architecture and settings of the YOLO model.\n",
    "model = YOLO('yolov8n.yaml')\n",
    "\n",
    "# The 'model' variable now contains a YOLO model ready for use in object detection tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ujavEsWUgKmT"
   },
   "outputs": [],
   "source": [
    "# Train the YOLO model with specified parameters\n",
    "# 'data' specifies the path to the data.yaml file which contains dataset configuration.\n",
    "# 'epochs' specifies the number of training epochs.\n",
    "# 'imgsz' specifies the input image size for training.\n",
    "results = model.train(data='/content/drive/MyDrive/dataset/data.yaml', epochs=202, imgsz=640)\n",
    "\n",
    "# The 'results' variable now contains the training results, such as loss values, metrics, and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_VnSw-OzgvYu"
   },
   "outputs": [],
   "source": [
    "# Load trained model for inference\n",
    "model = YOLO('/content/best.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4541,
     "status": "ok",
     "timestamp": 1697279251238,
     "user": {
      "displayName": "Saurabh Kushwaha",
      "userId": "11030038731599583514"
     },
     "user_tz": -330
    },
    "id": "yHGB3liihnVw",
    "outputId": "cc3f3d16-59fa-4ea6-d1ea-4ecf161eeba9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.198 ðŸš€ Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
      "Model summary (fused): 168 layers, 3005843 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\n",
      "image 1/1 /content/mawa.jpeg: 192x640 29 faces, 94.7ms\n",
      "Speed: 1.7ms preprocess, 94.7ms inference, 111.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict3\u001b[0m\n",
      "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/predict\n"
     ]
    }
   ],
   "source": [
    "! yolo task=detect mode=predict model=best.pt conf=0.25 max_det=100 source=/content/mawa.jpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1697279269462,
     "user": {
      "displayName": "Saurabh Kushwaha",
      "userId": "11030038731599583514"
     },
     "user_tz": -330
    },
    "id": "1QJ9WcBVqp5h",
    "outputId": "64f4deeb-aed8-4c3a-d095-abacf999fccc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 192x640 29 faces, 9.2ms\n",
      "Speed: 1.8ms preprocess, 9.2ms inference, 1.7ms postprocess per image at shape (1, 3, 192, 640)\n"
     ]
    }
   ],
   "source": [
    "results = model(['mawa.jpeg']) #best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 459,
     "status": "ok",
     "timestamp": 1697280098962,
     "user": {
      "displayName": "Saurabh Kushwaha",
      "userId": "11030038731599583514"
     },
     "user_tz": -330
    },
    "id": "Q5ZB-wJfxeHO",
    "outputId": "a7af9222-f9ea-41e3-a85b-7f74b36c78c5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /content/mawa.jpeg: 192x640 29 faces, 10.2ms\n",
      "Speed: 2.0ms preprocess, 10.2ms inference, 2.0ms postprocess per image at shape (1, 3, 192, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    }
   ],
   "source": [
    "detected_objects = []\n",
    "\n",
    "# Fectching the names of detected object\n",
    "result: Results = model.predict(\"mawa.jpeg\")[0]\n",
    "for box in result.boxes.data:\n",
    "    detected_objects.append(result.names.get(box[-1].item()))\n",
    "\n",
    "print(len(detected_objects))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 625
    },
    "executionInfo": {
     "elapsed": 2332,
     "status": "ok",
     "timestamp": 1697280120038,
     "user": {
      "displayName": "Saurabh Kushwaha",
      "userId": "11030038731599583514"
     },
     "user_tz": -330
    },
    "id": "yQsTvui7g1Hl",
    "outputId": "240e39b7-6e61-4b2b-e008-d2c3da90baa7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
      "\n",
      "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
      "Running on public URL: https://7fc1269ba66ba34430.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://7fc1269ba66ba34430.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def detect_objects(image):\n",
    "\n",
    "    detected_objects = []\n",
    "\n",
    "    # Fectching the names of detected object\n",
    "    result = model.predict(\"mawa.jpeg\")[0]\n",
    "    for box in result.boxes.data:\n",
    "        detected_objects.append(result.names.get(box[-1].item()))\n",
    "\n",
    "    return str(len(detected_objects))\n",
    "\n",
    "\n",
    "\n",
    "# Create a Gradio interface for object detection\n",
    "iface = gr.Interface(\n",
    "    fn=detect_objects,\n",
    "    inputs=\"image\",\n",
    "    outputs=\"text\",\n",
    "    title=\"YOLO face detection\",\n",
    "    description=\"Upload an image to detect objects using YOLO.\",\n",
    ")\n",
    "\n",
    "iface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N8YmbAgQoyly"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPzkepwidrfqW5mhNREqYMp",
   "gpuType": "T4",
   "provenance": [
    {
     "file_id": "1wKexDkrB8cieNgXOqpL2iIeVv660ADM-",
     "timestamp": 1697281401060
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
